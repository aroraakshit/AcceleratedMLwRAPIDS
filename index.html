<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Accelerated Machine Learning with RAPIDS</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<!-- Title Slide -->
				<section data-background-image=assets/imgs/opening_bg.png>
					<br>
					<img width=300 src=assets/imgs/RAPIDS_txt.png> <br>
					<strong>Accelerating Machine Learning with GPUs</strong>
					<p style="font-size:35px">Akshit Arora</p>
					<br><br><br><br>
					<p style="font-size:30px; color: #7306ff;">Data Scientist @ <img width=120 style="margin:0px; margin-bottom: -10px;" src=assets/imgs/nvidia.png> | <img width="50" style="margin:0px; margin-bottom: -15px;" src="assets/imgs/twitter.png"> @_AkshitArora </p>
				</section>

				<!-- What is ML? - Supervised & Unsupervised -->
				<section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<img width="700" src="assets/imgs/m_1_ml_xkcd.png">
						<p style="font-size:10px"><a href="https://twitter.com/kareem_carr/status/1122205223114686464">@quaesita</a></p>
					</section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<img width="700" src="assets/imgs/m_3_mlsup.png">
						<p style="font-size:10px"><a href="https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d">Supervised vs Unsupervised Learning</a></p>
					</section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<img width="700" src="assets/imgs/m_2_mlunsup.png">
						<p style="font-size:10px"><a href="https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d">Supervised vs Unsupervised Learning</a></p>
					</section>
				</section>

				<!-- Why accelerate ML? -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Speed, UX, and Iteration</p>
					<p style="font-size:25px;color: black;">The Way to Win at Data Science</p>
					<img width="700" src="assets/imgs/speed_ux_iteration.png">
				</section>

				<!-- ML Lifecycle / Table of Contents -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Machine Learning Lifecycle</p>
					<p style="font-size:25px;color: black;">Also, Table of Contents</p>
					<img width="700" src="assets/imgs/m_4_mll.png">
				</section>
				
				<!-- Random Forests - Intuition -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">Intuition</p>
					<div class="r-stack">
						<img class="fragment fade-out" width="300" src="assets/imgs/decision-tree.svg">
						<img class="fragment" width="700" src="assets/imgs/random-forest.svg">
					</div>
					<p style="font-size:10px"><a href="https://victorzhou.com/blog/intro-to-random-forests/">Random Forests for Complete Beginners</a></p>
				</section>

				<!-- Random Forests - Dataset -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">Example Dataset</p>
					<script src="https://gist.github.com/vishalmehta1991/1ba4a1ea0aa8a0af451be4f67f616d31.js"></script>
					<p style="font-size:10px"><a href="https://medium.com/rapids-ai/accelerating-random-forests-up-to-45x-using-cuml-dfb782a31bea">Accelerating Random Forests up to 45x using cuML</a></p>
				</section>

				<!-- Random Forests - Sub-sampled datasets -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Sub-sampled dataset 1 / 3</p>
						<script src="https://gist.github.com/vishalmehta1991/24141dadfe2e3ae5608c4e771ca7c933.js"></script>
					</section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Sub-sampled dataset 2 / 3</p>
						<script src="https://gist.github.com/vishalmehta1991/93012fd401cd7c8f50445708eec087db.js"></script>
					</section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Sub-sampled dataset 3 / 3</p>
						<script src="https://gist.github.com/vishalmehta1991/bdd858a23720d9b29f195f4957526163.js"></script>
					</section>
				</section>

				<section>
					<!-- Random Forests - building a decision tree -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Building a decision tree</p>
						<ol style="font-size:20px;color: black;">
							<li class="fragment">
								Finding the best particular split at a particular node involves two choices:
								<ol style="font-size:18px;color: black;">
									<li>the feature</li>
									<li>the split value for that feature</li>
								</ol>
								that will result in the <b>"highest improvement"</b> to the model.
							</li>
							<br>
							<li class="fragment">
								At each node, the algorithm uses a specified metric to estimate how much a potential split will improve the model.
								<ul style="font-size:18px;color: black;">
									<li>Classification task: <b>Gini Impurity</b> or Entropy.</li>
									<li>Regresion task: Mean Squared Error (MSE) or Mean Absolute Error (MAE)</li>
								</ul>
							</li>
							<br>
							<li class="fragment">Continue splitting the nodes until either:
								<ol style="font-size:18px;color: black;">
									<li>all values in the subset mapping to that node are pure (e.g. all fruits are strawberries)</li>
									OR
									<li>some other conditions are met (e.g. max tree depth, max number of samples per tree etc.)</li>
								</ol>
							</li>
						</ol>
					</section>
					<!-- Random Forests - backup slides for algorithmic details -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Measuring "Highest Improvement" at a split</p>
						<p style="font-size:20px;color: black;">A potential split S, defined by (feature split_value), will split this node’s dataset of ‘N’ rows into left and right subsets with N_left and N_right rows respectively. The improvement of Split S is computed as:</p>
						<p style="font-size:20px;color: black;font-style: italic;">improvement = Gini<sup> PARENT</sup> - impurity</p>
						<p style="font-size:20px;color: black;">where impurity is:</p>
						<p style="font-size:20px;color: black;font-style: italic;">impurity = N_left / N * Gini<sup> Left</sup> + N_right / N * Gini<sup> Right</sup></p>
					</section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">What is Gini Impurity?</p>
						<img width="600" src="assets/imgs/ml_6_randomForests.png">
						<img width="500" src="assets/imgs/ml_7_gini_formula.png">
						<p style="font-size:10px"><a href="https://medium.com/rapids-ai/accelerating-random-forests-up-to-45x-using-cuml-dfb782a31bea">EE596 by Linda Shapiro, CS@University of Washington</a></p>
					</section>
				</section>

				<!-- Random Forests - Independent Decision Trees -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">Independent Decision Trees</p>
					<img width="1000" src="assets/imgs/ml_5_randomForests1.png">
					<p style="font-size:10px"><a href="https://medium.com/rapids-ai/accelerating-random-forests-up-to-45x-using-cuml-dfb782a31bea">Accelerating Random Forests up to 45x using cuML</a></p>
				</section>

				<!-- Random Forests - sklearn implementation -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">sklearn implementation</p>
					<pre style="width: 1000px"><code class="language-python" style="word-wrap:normal" data-line-numbers="1-3|5-9|11-12|14-15" data-trim>
from sklearn.ensemble import RandomForestClassifier as sklRF
from sklearn.metrics import accuracy_scores
import multiprocessing as mp

skl_rf_params = {
	'n_estimators': 25,
	'max_depth': 13,
	'n_jobs': mp.cpu_count()
}

skl_rf = sklRF(**skl_rf_params)
skl_rf.fit(X_train, y_train)

y_pred = skl_rf.predict(X_test)
print("sklearn RF Accuracy Score: ", accuracy_score(y_pred, y_test))

					</code>
					</pre>
				</section>

				<section>
					<!-- Random Forests - Acceleration Opportunities -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Acceleration opportunities</p>
						<img width="200" src="assets/imgs/RAPIDS404.gif">
						<ol style="font-size:20px;color: black;">
							<li class="fragment">Independent decision tree development. Several trees can be built in parallel on a single GPU.</li>
							<br>
							<li class="fragment">Breadth-first approach, as opposed to depth-first. Building a full layer of the tree at a time.</li>
							<br>
							<li class="fragment">High performance split algorithms to select which values are explored for each feature+node combination.</li>
						</ol>
					</section>
					<!-- Random Forests - Split Algorithm details, backup -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Split Algorithm - Min/Max histograms</p>
						<ul style="font-size:20px;color: black;">
							<li>A histogram is built for every feature for a tree node. Every feature’s data range [min, max] is split into n_bins equally sized bins. The end range of each bin is considered as a potential split value. </li>
							<br>
							<li>With this approach, the split values for each feature are recomputed at each node, thus adapting to the data ranges at each tree node. </li>
							<br>
							<li>The min/max algorithm also helps in isolating outliers in the data at an early stage during the tree building process.</li>
						</ul>
					</section>
					<!-- Random Forests - Split Algorithm details, backup -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Split Algorithm - Quantiles</p>
						<ul style="font-size:20px;color: black;">
							<li>The quantiles split algorithm precomputes the potential split values for each feature once per tree, i.e., at the root node. Each feature (column) is sorted in ascending order, and split into n_bins such that each bin contains an equal portion of the root node’s dataset. The end range of each bin is considered as a potential split value. 
							</li>
							<br>
							<li>Thus, unlike min/max histograms where all bins have the same width, in quantiles all bins, except for the last one, have the same height for the root note, but are of variable width. As split values are precomputed once per tree, the quantile approach is faster than the min/max histogram algorithm.</li>
							<br>
							<li>If, for a node deep in the tree, all feature values fall under a single bin, then no splitting can take place for that feature. A further optimization (supported with the quantile_per_tree Python option) is to compute the split values once per random forest, i.e., for the original non-bootstrapped dataset, rather than once per decision tree. </li>
						</ul>
					</section>
				</section>

				<!-- Random Forests - Parallel Execution -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">Parallel Execution</p>
					<ol style="font-size:20px;color: black;">
						<li class="fragment">Initialize a bit mask indicating which samples are contained in each node.</li>
						<br>
						<li class="fragment">Initialize a "node map" indicating which nodes are present at each level.</li>
						<br>
						<li class="fragment">
							ForEach(tree_level):
							<ol style="font-size:18px;color: black;">
								<li class="fragment">Find the node id of all data samples, using the bit mask.</li>
								<li class="fragment">Compute the possible splits for all bins, all columns, and all nodes.</li>
								<li class="fragment">Find the best split for each node.</li>
								<li class="fragment">Update the bit mask and sparse node map to feed the next level.</li>
							</ol>
						</li>
					</ol>
				</section>

				<!-- Random Forests - cuML implementation -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">RAPIDS cuML implementation</p>
					<pre style="width: 1000px"><code class="language-python" style="word-wrap:normal" data-line-numbers="1|3-8|10-11|13-14" data-trim>
from cuML import RandomForestClassifier as cuRF

cu_rf_params = {
	'n_estimators': 25,
	'max_depth': 13,
	'max_features': 8,
	'n_bins': 15
}

cu_rf = cuRF(**cu_rf_params)
cu_rf.fit(X_train, y_train)

y_pred = cu_rf.predict(X_test)
print("cuML RF Accuracy Score: ", accuracy_score(y_pred, y_test))
					</code>
					</pre>
				</section>

				<section>
					<!-- Speedups - 1 -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Results - Benchmark Details</p>
						<ul style="font-size:20px;color: black;">
							<li>
								RAPIDS cuML version 0.10 (single V100 16 GB GPU; with cuDF) vs. sklearn version 0.21.2 (80 CPU threads; with numpy).
							</li>
							<br>
							<li>
								NVIDIA DGX-1 server with 8 x V100 (16 GB) GPUs and dual Xeon E5-2698v4@2.20GHz CPUs with 40 CPU cores in total. 
							</li>
							<br>
							<li>
								Higgs Dataset: 28 columns and 11M rows (randomly chosen 10.5M for training and 1000 rows for testing).
							</li>
						</ul>
					</section>
					<!-- Speedups - 2 -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Results - Higgs Dataset</p>
						<img width="700" src="assets/imgs/res_higgs.png">
					</section>
					<!-- Speedups - 3 -->
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Random Forests</p>
						<p style="font-size:25px;color: black;">Results - Synthetic Dataset</p>
						<img width="700" src="assets/imgs/res_synthetic.png">
					</section>
				</section>

				<!-- Data Processing Evolution -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Data Processing Evolution</p>
					<p style="font-size:25px;color: black;">Faster Data Access, Less Data Movement</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" width="700" src="assets/imgs/dpe_1.png">
						<img class="fragment fade-in-then-out fade-up" width="700" src="assets/imgs/dpe_2.png">
						<img class="fragment fade-in-then-out fade-up" width="700" src="assets/imgs/dpe_3.png">
					</div>
				</section>
				
				<!-- Data Movement and Transformation -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Data Movement and Transformation</p>
					<p style="font-size:25px;color: black;">The Bane of Productivity and Performance</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" width="700" src="assets/imgs/dmt_1.png">
						<img class="fragment fade-in-then-out" width="700" src="assets/imgs/dmt_2.png">
					</div>
				</section>

				<!-- Learning from Apache Arrow -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Learning from Apache Arrow</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" width="700" src="assets/imgs/laa_2.png">
						<img class="fragment fade-in-then-out" width="700" src="assets/imgs/laa_3.png">
					</div>
				</section>

				<!-- Data Processing Evolution Revisited -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Data Processing Evolution</p>
					<p style="font-size:25px;color: black;">Faster Data Access, Less Data Movement</p>
					<div class="r-stack">
						<img class="fragment fade-in-then-out" width="700" src="assets/imgs/dpe_3.png">
						<img class="fragment fade-in-then-out fade-up" width="700" src="assets/imgs/dpe_4.png">
					</div>
				</section>

				<!-- Current Libraries -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Open Source Data Science Ecosystem</p>
					<p style="font-size:25px;color: black;">Familiar Python APIs</p>
					<img width="700" src="assets/imgs/cl_1.png">
				</section>

				<!-- RAPIDS Libraries -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">RAPIDS</p>
					<p style="font-size:25px;color: black;">End-to-End GPU Accelerated Data Science</p>
					<img width="700" src="assets/imgs/ra_1.png">
				</section>

				<!-- Random Forests cuDF implementation -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">Using cuDF for data loading</p>
					<pre style="width: 1000px"><code class="language-python" style="word-wrap:normal" data-line-numbers="2-3|5-7|9-20" data-trim>
from cuML import RandomForestClassifier as cuRF
from cuml.preprocessing.model_selection import train_test_split
import cudf

data = cudf.read_csv('dataset.csv')
X_train, X_test, y_train, y_test = \
    train_test_split(data, 'label', train_size=0.8)

cu_rf_params = {
	'n_estimators': 25,
	'max_depth': 13,
	'max_features': 8,
	'n_bins': 15
}

cu_rf = cuRF(**cu_rf_params)
cu_rf.fit(X_train, y_train)

y_pred = cu_rf.predict(X_test)
print("cuML RF Accuracy Score: ", accuracy_score(y_pred, y_test))
					</code>
					</pre>
				</section>

				<!-- Benefits of cuDF -->
				<section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">Why cuDF?</p>
						<img width="700" src="assets/imgs/cudf_1.png">
					</section>
					<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
						<p style="font-size:50px;color: #7306ff;">cuDF Benchmarks</p>
						<img width="700" src="assets/imgs/cudf_2.png">
					</section>
				</section>

				<!-- Random Forests Dask cuML implementation -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">Dask cuML implementation</p>
					<pre style="width: 1000px"><code class="language-python" style="word-wrap:normal" data-line-numbers="1-5|7-14|16-20|22-25|27-34|36-47|49-52" data-trim>
from cuml.dask.common import utils as dask_utils
from dask.distributed import Client, wait
from dask_cuda import LocalCUDACluster
import dask_cudf
from cuml.dask.ensemble import RandomForestClassifier as cumlDaskRF

# This will use all GPUs on the local host by default
cluster = LocalCUDACluster(threads_per_worker=1)
c = Client(cluster)

# Query the client for all connected workers
workers = c.has_what().keys()
n_workers = len(workers)
n_streams = 8 # Performance optimization

# Data parameters
train_size = 100000
test_size = 1000
n_samples = train_size + test_size
n_features = 20

# Random Forest building parameters
max_depth = 12
n_bins = 16
n_trees = 1000

# Generate Data on host
X, y = datasets.make_classification(n_samples=n_samples, n_features=n_features,
                                 n_clusters_per_class=1, n_informative=int(n_features / 3),
                                 random_state=123, n_classes=5)
y = y.astype(np.int32)
X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)

n_partitions = n_workers

# First convert to cudf (with real data, you would likely load in cuDF format to start)
X_train_cudf = cudf.DataFrame.from_pandas(pd.DataFrame(X_train))
y_train_cudf = cudf.Series(y_train)

# Partition with Dask
# In this case, each worker will train on 1/n_partitions fraction of the data
X_train_dask = dask_cudf.from_cudf(X_train_cudf, npartitions=n_partitions)
y_train_dask = dask_cudf.from_cudf(y_train_cudf, npartitions=n_partitions)

# Persist to cache the data in active memory
X_train_dask, y_train_dask = \
  dask_utils.persist_across_workers(c, [X_train_dask, y_train_dask], workers=workers)

cuml_model = cumlDaskRF(max_depth=max_depth, n_estimators=n_trees, n_bins=n_bins, n_streams=n_streams)
cuml_model.fit(X_train_dask, y_train_dask)

wait(cuml_model.rfs) # Allow asynchronous training tasks to finish
					</code>
					</pre>
					<p style="font-size:10px"><a href="https://github.com/rapidsai/cuml/blob/branch-0.15/notebooks/random_forest_mnmg_demo.ipynb">random_forest_mnmg_demo.ipynb</a></p>
				</section>

				<!-- Forest Inference Library -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Random Forests</p>
					<p style="font-size:25px;color: black;">Forest Inference Library implementation</p>
					<pre style="width: 1000px"><code class="language-python" style="word-wrap:normal" data-line-numbers="1|3-7|9-10" data-trim>
from cuml import ForestInference

fm = ForestInference.load(filename=model_path,
algo='BATCH_TREE_REORG',
output_class=True,
threshold=0.50,
model_type='xgboost')

# perform prediction on the model loaded from path
fil_preds = fm.predict(X_validation)
					</code>
					</pre>
					<p style="font-size:10px"><a href="https://github.com/rapidsai/cuml/blob/branch-0.15/notebooks/forest_inference_demo.ipynb">forest_inference_demo.ipynb</a></p>
				</section>
				
				<!-- Hyper Parameter Optimization -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Hyper Parameter Optimization w/ RAPIDS</p>
					<img width="700" src="assets/imgs/rapids_hpo.png">
				</section>

				<!-- Summary -->
				<section data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<p style="font-size:50px;color: #7306ff;">Today we learned!</p>
					<img width="700" src="assets/imgs/end-1.png">
				</section>
				
				<!-- <section data-markdown data-background-image="assets/imgs/another_bg_1.png" data-background="white">
					<script type="text/template">
					  New Slide
					</script>
				</section> -->
			
				<section data-markdown data-background-image="assets/imgs/closing_bg.png">
					<script type="text/template">
					  <img width=300 src=assets/imgs/RAPIDS_txt.png> <br>
					  ## Thank you for joining!
					  <p style="font-size:30px"><img width="50" style="margin:0px; margin-bottom: -15px;" src="assets/imgs/twitter.png"> <a href="https://twitter.com/_AkshitArora">@_AkshitArora </a> </p>
					  <p style="font-size:30px"> <img width="50" style="margin:0px; margin-bottom: -15px;" src="assets/imgs/github.png"> <a href="https://aroraakshit.github.io/AcceleratedMLwRAPIDS/">aroraakshit/AcceleratedMLwRAPIDS</a> </p>
					</script>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				slideNumber: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
